{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2531927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# --- Configuration ---\n",
    "# NOTE: This script assumes you have authenticated with Google Cloud.\n",
    "# If running locally, you can typically run 'gcloud auth application-default login'\n",
    "# in your terminal first.\n",
    "\n",
    "PROJECT_ID = \"celtic-fact-367202\"\n",
    "DATASET_ID = \"test\"\n",
    "SOURCE_TABLE_ID = \"pokemon\"\n",
    "DESTINATION_TABLE_ID = \"new_pokemon_data\" # New table to demonstrate the push/upload function\n",
    "\n",
    "def fetch_data(client: bigquery.Client, table_id: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches all data from the specified BigQuery table into a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    full_table_path = f\"{PROJECT_ID}.{DATASET_ID}.{table_id}\"\n",
    "    print(f\"Fetching data from: {full_table_path}...\")\n",
    "\n",
    "    # A simple SQL query to select all data\n",
    "    sql_query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM `{full_table_path}`\n",
    "        LIMIT 100  -- Limiting the fetch for demonstration purposes\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # The to_dataframe() method handles the job execution and result fetching\n",
    "        df = client.query(sql_query).to_dataframe()\n",
    "        print(f\"Successfully fetched {len(df)} rows.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data fetch: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def generate_mock_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a mock DataFrame that conforms to the 'pokemon' table schema\n",
    "    for the purpose of demonstrating the 'push' operation.\n",
    "    \"\"\"\n",
    "    print(\"Generating mock data for upload...\")\n",
    "    new_data = [\n",
    "        {'#': 1001, 'Name': 'Pikachu Prime', 'Type 1': 'Electric', 'Type 2': None, 'HP': 150, 'Attack': 120, 'Defense': 90, 'Sp_Atk': 150, 'Sp_Def': 90, 'Speed': 180, 'Generation': 10, 'Legendary': True},\n",
    "        {'#': 1002, 'Name': 'Bulbasaur Beta', 'Type 1': 'Grass', 'Type 2': 'Poison', 'HP': 100, 'Attack': 70, 'Defense': 70, 'Sp_Atk': 80, 'Sp_Def': 100, 'Speed': 60, 'Generation': 10, 'Legendary': False},\n",
    "    ]\n",
    "\n",
    "    # The columns MUST match the schema of the target BigQuery table\n",
    "    columns = ['#', 'Name', 'Type 1', 'Type 2', 'HP', 'Attack', 'Defense', 'Sp_Atk', 'Sp_Def', 'Speed', 'Generation', 'Legendary']\n",
    "    df = pd.DataFrame(new_data, columns=columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def push_data(client: bigquery.Client, df: pd.DataFrame, table_id: str):\n",
    "    \"\"\"\n",
    "    Pushes data from a Pandas DataFrame to a specified BigQuery table.\n",
    "    It will create the table if it does not exist.\n",
    "    \"\"\"\n",
    "    full_table_path = f\"{PROJECT_ID}.{DATASET_ID}.{table_id}\"\n",
    "    print(f\"\\nAttempting to push {len(df)} rows to: {full_table_path}...\")\n",
    "\n",
    "    # Configure the job\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        # Set write disposition:\n",
    "        # WRITE_TRUNCATE: Overwrites the table.\n",
    "        # WRITE_APPEND: Appends to the table.\n",
    "        # WRITE_EMPTY: Fails if the table is not empty.\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Start the load job\n",
    "        job = client.load_table_from_dataframe(\n",
    "            df, full_table_path, job_config=job_config\n",
    "        )\n",
    "        job.result()  # Wait for the job to complete\n",
    "\n",
    "        table = client.get_table(full_table_path)\n",
    "        print(f\"Successfully loaded {table.num_rows} rows into {full_table_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data push: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the BigQuery operations.\"\"\"\n",
    "    try:\n",
    "        # Initialize the BigQuery client\n",
    "        client = bigquery.Client()\n",
    "    except Exception as e:\n",
    "        print(\"Failed to initialize BigQuery client.\")\n",
    "        print(\"Please ensure your Google Cloud environment is authenticated.\")\n",
    "        print(f\"Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # 1. GET DATA\n",
    "    pokemon_df = fetch_data(client, SOURCE_TABLE_ID)\n",
    "\n",
    "    if not pokemon_df.empty:\n",
    "        print(\"\\n--- Sample of Fetched Data ---\")\n",
    "        print(pokemon_df.head())\n",
    "    else:\n",
    "        print(\"Could not proceed without fetching data.\")\n",
    "        return\n",
    "\n",
    "    # 2. PUSH DATA\n",
    "    # Create the new data to push\n",
    "    new_pokemon_data_df = generate_mock_data()\n",
    "\n",
    "    # Upload the new data to the destination table\n",
    "    push_data(client, new_pokemon_data_df, DESTINATION_TABLE_ID)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
